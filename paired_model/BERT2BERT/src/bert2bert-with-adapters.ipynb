{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:30:37.933426Z"},"trusted":true},"outputs":[],"source":["# !pip install git+https://github.com/adapter-hub/adapters.git\n","# !pip install wandb\n","# !pip install pandas\n","# !pip install datasets\n","\n","# requires ipykernel package"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install accelerate -U"]},{"cell_type":"code","execution_count":11,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["from transformers import BertGenerationEncoder, BertGenerationDecoder, EncoderDecoderModel, Seq2SeqTrainingArguments, BertTokenizer, Seq2SeqTrainer, AutoModel, AutoModelForCausalLM, DataCollatorForSeq2Seq, GenerationConfig, DataCollatorWithPadding\n","from adapters import BnConfig, Seq2SeqAdapterTrainer, AdapterTrainer, BertAdapterModel, init\n","import wandb\n","import torch\n","import pandas as pd\n","from datasets import Dataset\n","import os\n","import datasets\n","import numpy as np\n","import re"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["device: cuda\n"]}],"source":["# print device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"device: {device}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Some weights of BertModel were not initialized from the model checkpoint at Exscientia/IgBert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertLMHeadModel were not initialized from the model checkpoint at Exscientia/IgBert and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.12.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.12.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.12.crossattention.output.dense.bias', 'bert.encoder.layer.12.crossattention.output.dense.weight', 'bert.encoder.layer.12.crossattention.self.key.bias', 'bert.encoder.layer.12.crossattention.self.key.weight', 'bert.encoder.layer.12.crossattention.self.query.bias', 'bert.encoder.layer.12.crossattention.self.query.weight', 'bert.encoder.layer.12.crossattention.self.value.bias', 'bert.encoder.layer.12.crossattention.self.value.weight', 'bert.encoder.layer.13.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.13.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.13.crossattention.output.dense.bias', 'bert.encoder.layer.13.crossattention.output.dense.weight', 'bert.encoder.layer.13.crossattention.self.key.bias', 'bert.encoder.layer.13.crossattention.self.key.weight', 'bert.encoder.layer.13.crossattention.self.query.bias', 'bert.encoder.layer.13.crossattention.self.query.weight', 'bert.encoder.layer.13.crossattention.self.value.bias', 'bert.encoder.layer.13.crossattention.self.value.weight', 'bert.encoder.layer.14.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.14.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.14.crossattention.output.dense.bias', 'bert.encoder.layer.14.crossattention.output.dense.weight', 'bert.encoder.layer.14.crossattention.self.key.bias', 'bert.encoder.layer.14.crossattention.self.key.weight', 'bert.encoder.layer.14.crossattention.self.query.bias', 'bert.encoder.layer.14.crossattention.self.query.weight', 'bert.encoder.layer.14.crossattention.self.value.bias', 'bert.encoder.layer.14.crossattention.self.value.weight', 'bert.encoder.layer.15.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.15.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.15.crossattention.output.dense.bias', 'bert.encoder.layer.15.crossattention.output.dense.weight', 'bert.encoder.layer.15.crossattention.self.key.bias', 'bert.encoder.layer.15.crossattention.self.key.weight', 'bert.encoder.layer.15.crossattention.self.query.bias', 'bert.encoder.layer.15.crossattention.self.query.weight', 'bert.encoder.layer.15.crossattention.self.value.bias', 'bert.encoder.layer.15.crossattention.self.value.weight', 'bert.encoder.layer.16.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.16.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.16.crossattention.output.dense.bias', 'bert.encoder.layer.16.crossattention.output.dense.weight', 'bert.encoder.layer.16.crossattention.self.key.bias', 'bert.encoder.layer.16.crossattention.self.key.weight', 'bert.encoder.layer.16.crossattention.self.query.bias', 'bert.encoder.layer.16.crossattention.self.query.weight', 'bert.encoder.layer.16.crossattention.self.value.bias', 'bert.encoder.layer.16.crossattention.self.value.weight', 'bert.encoder.layer.17.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.17.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.17.crossattention.output.dense.bias', 'bert.encoder.layer.17.crossattention.output.dense.weight', 'bert.encoder.layer.17.crossattention.self.key.bias', 'bert.encoder.layer.17.crossattention.self.key.weight', 'bert.encoder.layer.17.crossattention.self.query.bias', 'bert.encoder.layer.17.crossattention.self.query.weight', 'bert.encoder.layer.17.crossattention.self.value.bias', 'bert.encoder.layer.17.crossattention.self.value.weight', 'bert.encoder.layer.18.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.18.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.18.crossattention.output.dense.bias', 'bert.encoder.layer.18.crossattention.output.dense.weight', 'bert.encoder.layer.18.crossattention.self.key.bias', 'bert.encoder.layer.18.crossattention.self.key.weight', 'bert.encoder.layer.18.crossattention.self.query.bias', 'bert.encoder.layer.18.crossattention.self.query.weight', 'bert.encoder.layer.18.crossattention.self.value.bias', 'bert.encoder.layer.18.crossattention.self.value.weight', 'bert.encoder.layer.19.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.19.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.19.crossattention.output.dense.bias', 'bert.encoder.layer.19.crossattention.output.dense.weight', 'bert.encoder.layer.19.crossattention.self.key.bias', 'bert.encoder.layer.19.crossattention.self.key.weight', 'bert.encoder.layer.19.crossattention.self.query.bias', 'bert.encoder.layer.19.crossattention.self.query.weight', 'bert.encoder.layer.19.crossattention.self.value.bias', 'bert.encoder.layer.19.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.20.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.20.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.20.crossattention.output.dense.bias', 'bert.encoder.layer.20.crossattention.output.dense.weight', 'bert.encoder.layer.20.crossattention.self.key.bias', 'bert.encoder.layer.20.crossattention.self.key.weight', 'bert.encoder.layer.20.crossattention.self.query.bias', 'bert.encoder.layer.20.crossattention.self.query.weight', 'bert.encoder.layer.20.crossattention.self.value.bias', 'bert.encoder.layer.20.crossattention.self.value.weight', 'bert.encoder.layer.21.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.21.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.21.crossattention.output.dense.bias', 'bert.encoder.layer.21.crossattention.output.dense.weight', 'bert.encoder.layer.21.crossattention.self.key.bias', 'bert.encoder.layer.21.crossattention.self.key.weight', 'bert.encoder.layer.21.crossattention.self.query.bias', 'bert.encoder.layer.21.crossattention.self.query.weight', 'bert.encoder.layer.21.crossattention.self.value.bias', 'bert.encoder.layer.21.crossattention.self.value.weight', 'bert.encoder.layer.22.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.22.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.22.crossattention.output.dense.bias', 'bert.encoder.layer.22.crossattention.output.dense.weight', 'bert.encoder.layer.22.crossattention.self.key.bias', 'bert.encoder.layer.22.crossattention.self.key.weight', 'bert.encoder.layer.22.crossattention.self.query.bias', 'bert.encoder.layer.22.crossattention.self.query.weight', 'bert.encoder.layer.22.crossattention.self.value.bias', 'bert.encoder.layer.22.crossattention.self.value.weight', 'bert.encoder.layer.23.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.23.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.23.crossattention.output.dense.bias', 'bert.encoder.layer.23.crossattention.output.dense.weight', 'bert.encoder.layer.23.crossattention.self.key.bias', 'bert.encoder.layer.23.crossattention.self.key.weight', 'bert.encoder.layer.23.crossattention.self.query.bias', 'bert.encoder.layer.23.crossattention.self.query.weight', 'bert.encoder.layer.23.crossattention.self.value.bias', 'bert.encoder.layer.23.crossattention.self.value.weight', 'bert.encoder.layer.24.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.24.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.24.crossattention.output.dense.bias', 'bert.encoder.layer.24.crossattention.output.dense.weight', 'bert.encoder.layer.24.crossattention.self.key.bias', 'bert.encoder.layer.24.crossattention.self.key.weight', 'bert.encoder.layer.24.crossattention.self.query.bias', 'bert.encoder.layer.24.crossattention.self.query.weight', 'bert.encoder.layer.24.crossattention.self.value.bias', 'bert.encoder.layer.24.crossattention.self.value.weight', 'bert.encoder.layer.25.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.25.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.25.crossattention.output.dense.bias', 'bert.encoder.layer.25.crossattention.output.dense.weight', 'bert.encoder.layer.25.crossattention.self.key.bias', 'bert.encoder.layer.25.crossattention.self.key.weight', 'bert.encoder.layer.25.crossattention.self.query.bias', 'bert.encoder.layer.25.crossattention.self.query.weight', 'bert.encoder.layer.25.crossattention.self.value.bias', 'bert.encoder.layer.25.crossattention.self.value.weight', 'bert.encoder.layer.26.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.26.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.26.crossattention.output.dense.bias', 'bert.encoder.layer.26.crossattention.output.dense.weight', 'bert.encoder.layer.26.crossattention.self.key.bias', 'bert.encoder.layer.26.crossattention.self.key.weight', 'bert.encoder.layer.26.crossattention.self.query.bias', 'bert.encoder.layer.26.crossattention.self.query.weight', 'bert.encoder.layer.26.crossattention.self.value.bias', 'bert.encoder.layer.26.crossattention.self.value.weight', 'bert.encoder.layer.27.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.27.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.27.crossattention.output.dense.bias', 'bert.encoder.layer.27.crossattention.output.dense.weight', 'bert.encoder.layer.27.crossattention.self.key.bias', 'bert.encoder.layer.27.crossattention.self.key.weight', 'bert.encoder.layer.27.crossattention.self.query.bias', 'bert.encoder.layer.27.crossattention.self.query.weight', 'bert.encoder.layer.27.crossattention.self.value.bias', 'bert.encoder.layer.27.crossattention.self.value.weight', 'bert.encoder.layer.28.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.28.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.28.crossattention.output.dense.bias', 'bert.encoder.layer.28.crossattention.output.dense.weight', 'bert.encoder.layer.28.crossattention.self.key.bias', 'bert.encoder.layer.28.crossattention.self.key.weight', 'bert.encoder.layer.28.crossattention.self.query.bias', 'bert.encoder.layer.28.crossattention.self.query.weight', 'bert.encoder.layer.28.crossattention.self.value.bias', 'bert.encoder.layer.28.crossattention.self.value.weight', 'bert.encoder.layer.29.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.29.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.29.crossattention.output.dense.bias', 'bert.encoder.layer.29.crossattention.output.dense.weight', 'bert.encoder.layer.29.crossattention.self.key.bias', 'bert.encoder.layer.29.crossattention.self.key.weight', 'bert.encoder.layer.29.crossattention.self.query.bias', 'bert.encoder.layer.29.crossattention.self.query.weight', 'bert.encoder.layer.29.crossattention.self.value.bias', 'bert.encoder.layer.29.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"Exscientia/IgBert\", \"Exscientia/IgBert\", add_cross_attention=True)\n","init(model)"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["config = BnConfig(mh_adapter=True, output_adapter=True, reduction_factor=16, non_linearity=\"relu\")\n","\n","model.add_adapter(\"seq2seq_adapter\", config=config)\n","model.set_active_adapters(\"seq2seq_adapter\")\n","model.train_adapter(\"seq2seq_adapter\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["<bound method Module.named_parameters of EncoderDecoderModelWithAdapters(\n","  (encoder): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(40000, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-29): 30 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttentionWithAdapters(\n","              (query): LoRALinearTorch(\n","                in_features=1024, out_features=1024, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): LoRALinearTorch(\n","                in_features=1024, out_features=1024, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): LoRALinearTorch(\n","                in_features=1024, out_features=1024, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","              (prefix_tuning): PrefixTuningLayer(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): BertSelfOutputWithAdapters(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","              (adapters): ModuleDict(\n","                (seq2seq_adapter): Adapter(\n","                  (non_linearity): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                  (adapter_down): Sequential(\n","                    (0): Linear(in_features=1024, out_features=64, bias=True)\n","                    (1): Activation_Function_Class(\n","                      (f): ReLU()\n","                    )\n","                  )\n","                  (adapter_up): Linear(in_features=64, out_features=1024, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): LoRALinearTorch(\n","              in_features=1024, out_features=4096, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutputWithAdapters(\n","            (dense): LoRALinearTorch(\n","              in_features=4096, out_features=1024, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (adapters): ModuleDict(\n","              (seq2seq_adapter): Adapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=1024, out_features=64, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=64, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","      (activation): Tanh()\n","    )\n","    (invertible_adapters): ModuleDict()\n","    (shared_parameters): ModuleDict()\n","    (prefix_tuning): PrefixTuningPool(\n","      (prefix_tunings): ModuleDict()\n","    )\n","    (prompt_tuning): PromptTuningLayer(\n","      (base_model_embeddings): Embedding(30, 1024, padding_idx=0)\n","      (prompt_tunings): ModuleDict()\n","    )\n","  )\n","  (decoder): BertLMHeadModel(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30, 1024, padding_idx=0)\n","        (position_embeddings): Embedding(40000, 1024)\n","        (token_type_embeddings): Embedding(2, 1024)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0-29): 30 x BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttentionWithAdapters(\n","                (query): LoRALinearTorch(\n","                  in_features=1024, out_features=1024, bias=True\n","                  (loras): ModuleDict()\n","                )\n","                (key): LoRALinearTorch(\n","                  in_features=1024, out_features=1024, bias=True\n","                  (loras): ModuleDict()\n","                )\n","                (value): LoRALinearTorch(\n","                  in_features=1024, out_features=1024, bias=True\n","                  (loras): ModuleDict()\n","                )\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (prefix_tuning): PrefixTuningLayer(\n","                  (prefix_gates): ModuleDict()\n","                  (pool): PrefixTuningPool(\n","                    (prefix_tunings): ModuleDict()\n","                  )\n","                )\n","              )\n","              (output): BertSelfOutputWithAdapters(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (adapters): ModuleDict(\n","                  (seq2seq_adapter): Adapter(\n","                    (non_linearity): Activation_Function_Class(\n","                      (f): ReLU()\n","                    )\n","                    (adapter_down): Sequential(\n","                      (0): Linear(in_features=1024, out_features=64, bias=True)\n","                      (1): Activation_Function_Class(\n","                        (f): ReLU()\n","                      )\n","                    )\n","                    (adapter_up): Linear(in_features=64, out_features=1024, bias=True)\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                )\n","                (adapter_fusion_layer): ModuleDict()\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttentionWithAdapters(\n","                (query): LoRALinearTorch(\n","                  in_features=1024, out_features=1024, bias=True\n","                  (loras): ModuleDict()\n","                )\n","                (key): LoRALinearTorch(\n","                  in_features=1024, out_features=1024, bias=True\n","                  (loras): ModuleDict()\n","                )\n","                (value): LoRALinearTorch(\n","                  in_features=1024, out_features=1024, bias=True\n","                  (loras): ModuleDict()\n","                )\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (prefix_tuning): PrefixTuningLayer(\n","                  (prefix_gates): ModuleDict()\n","                  (pool): PrefixTuningPool(\n","                    (prefix_tunings): ModuleDict()\n","                  )\n","                )\n","              )\n","              (output): BertSelfOutputWithAdapters(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (adapters): ModuleDict(\n","                  (seq2seq_adapter): Adapter(\n","                    (non_linearity): Activation_Function_Class(\n","                      (f): ReLU()\n","                    )\n","                    (adapter_down): Sequential(\n","                      (0): Linear(in_features=1024, out_features=64, bias=True)\n","                      (1): Activation_Function_Class(\n","                        (f): ReLU()\n","                      )\n","                    )\n","                    (adapter_up): Linear(in_features=64, out_features=1024, bias=True)\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                )\n","                (adapter_fusion_layer): ModuleDict()\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): LoRALinearTorch(\n","                in_features=1024, out_features=4096, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutputWithAdapters(\n","              (dense): LoRALinearTorch(\n","                in_features=4096, out_features=1024, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","              (adapters): ModuleDict(\n","                (seq2seq_adapter): Adapter(\n","                  (non_linearity): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                  (adapter_down): Sequential(\n","                    (0): Linear(in_features=1024, out_features=64, bias=True)\n","                    (1): Activation_Function_Class(\n","                      (f): ReLU()\n","                    )\n","                  )\n","                  (adapter_up): Linear(in_features=64, out_features=1024, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","        )\n","      )\n","      (shared_parameters): ModuleDict()\n","      (invertible_adapters): ModuleDict()\n","      (prefix_tuning): PrefixTuningPool(\n","        (prefix_tunings): ModuleDict()\n","      )\n","      (prompt_tuning): PromptTuningLayer(\n","        (base_model_embeddings): Embedding(30, 1024, padding_idx=0)\n","        (prompt_tunings): ModuleDict()\n","      )\n","    )\n","    (cls): BertOnlyMLMHead(\n","      (predictions): BertLMPredictionHead(\n","        (transform): BertPredictionHeadTransform(\n","          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","          (transform_act_fn): GELUActivation()\n","          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (decoder): Linear(in_features=1024, out_features=30, bias=True)\n","      )\n","    )\n","  )\n","  (invertible_adapters): ModuleDict()\n","  (shared_parameters): ModuleDict()\n",")>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model.named_parameters"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Loop through all parameters and enable gradient computation only for 'crossattention' parameters\n","for name, param in model.named_parameters():\n","    if re.match(\".*crossattention.*\", name):\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False  # Assuming you want to freeze other parameters\n","\n","# Your model is now set up to train only the cross-attention layers and the added adapter."]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["#print(f\"print EncoderDecoderModel: {model}\")\n","\n","# Load the tokenizer and model from Hugging Face\n","tokenizer = BertTokenizer.from_pretrained(\"Exscientia/IgBert\")"]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":true},"outputs":[],"source":["generation_config = GenerationConfig(\n","    num_return_sequences=1,\n","    max_length=512,\n","    min_length=50,\n","    early_stopping = True,\n","    \n","    length_penalty = -2.0,\n","    \n","    num_beams = 3,\n","\n","    # sampling\n","    do_sample=True,\n","    top_k=50,\n","    \n","    no_repeat_ngram_size = 2,\n","\n","    # distribution adjustment\n","    temperature=0.001,\n","    repetition_penalty=1,\n","\n","    vocab_size=model.config.encoder.vocab_size,\n","\n","    # token ids\n","    pad_token_id=tokenizer.pad_token_id,\n","    eos_token_id=tokenizer.sep_token_id,\n","    decoder_start_token_id=tokenizer.cls_token_id,\n","\n","    # others\n","    use_cache=True,\n","    output_logits=True,\n","    output_scores=True,\n","    output_hidden_states=True,\n","    return_dict_in_generate=True, )\n"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[],"source":["generation_config.save_pretrained(\"generation_config\", \"generation_config_5.json\")"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[],"source":["generation_config_name = \"generation_config_5\"\n","generation_config = GenerationConfig.from_pretrained(\"generation_config\", f\"{generation_config_name}.json\")"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 32\n","num_train_epochs = 3\n","learning_rate = 1e-4\n","\n","\n","# Set up the run name\n","run_name=f\"freeze_small_data_with_adapters_batch_size_{batch_size}_epochs_{num_train_epochs}_automodel_lr_{learning_rate}_{generation_config_name}\"\n","\n","output_dir = f\"./{run_name}\"\n","logging_dir = f\"./{run_name}_logging\""]},{"cell_type":"code","execution_count":40,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:m64bc36y) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">freeze_small_data_with_adapters_batch_size_32_epochs_3_automodel_lr_0.0001_generation_config_4</strong> at: <a href='https://wandb.ai/ibmm-unibe-ch/bert2bert-translation/runs/m64bc36y' target=\"_blank\">https://wandb.ai/ibmm-unibe-ch/bert2bert-translation/runs/m64bc36y</a><br/> View project at: <a href='https://wandb.ai/ibmm-unibe-ch/bert2bert-translation' target=\"_blank\">https://wandb.ai/ibmm-unibe-ch/bert2bert-translation</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240703_133319-m64bc36y/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:m64bc36y). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2BERT/src/wandb/run-20240703_133508-3zhy4kd6</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/ibmm-unibe-ch/bert2bert-translation/runs/3zhy4kd6' target=\"_blank\">freeze_small_data_with_adapters_batch_size_32_epochs_3_automodel_lr_0.0001_generation_config_5</a></strong> to <a href='https://wandb.ai/ibmm-unibe-ch/bert2bert-translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/ibmm-unibe-ch/bert2bert-translation' target=\"_blank\">https://wandb.ai/ibmm-unibe-ch/bert2bert-translation</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/ibmm-unibe-ch/bert2bert-translation/runs/3zhy4kd6' target=\"_blank\">https://wandb.ai/ibmm-unibe-ch/bert2bert-translation/runs/3zhy4kd6</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ibmm-unibe-ch/bert2bert-translation/runs/3zhy4kd6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f2055779e20>"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=output_dir,\n","    logging_dir=logging_dir,\n","    evaluation_strategy=\"steps\",\n","    logging_strategy=\"steps\",\n","    logging_steps=10,\n","    learning_rate=learning_rate,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=num_train_epochs,\n","    predict_with_generate=True,\n","    report_to=\"wandb\",\n","    run_name=run_name,\n","    generation_config=generation_config,\n",")\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","# Create directories if they do not exist\n","os.makedirs(training_args.output_dir, exist_ok=True)\n","os.makedirs(training_args.logging_dir, exist_ok=True)\n","\n","# Log in to Weights & Biases\n","#wandb.login()\n","\n","\n","wandb.init(project=\"bert2bert-translation\", name=run_name)"]},{"cell_type":"code","execution_count":41,"metadata":{"trusted":true},"outputs":[],"source":["def load_data(file_path):\n","    data = []\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            data.append(line.strip())\n","\n","    sequences = []\n","    for entry in data:\n","        split_entry = entry.split(' [SEP] ')\n","        if (len(split_entry) == 2):\n","            sequences.append(split_entry)\n","        else:\n","            print(f\"Skipping invalid entry: {entry}\")\n","\n","    df = pd.DataFrame(sequences, columns=['heavy', 'light'])\n","    return df\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip show datasets\n"]},{"cell_type":"code","execution_count":42,"metadata":{"trusted":true},"outputs":[],"source":["# Load training and validation data\n","\n","train_file_path = '/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2BERT/data/paired_full_seqs_sep_train_no_ids_small_SPACE_separated.txt'\n","val_file_path = '/ibmm_data2/oas_database/paired_lea_tmp/paired_model/BERT2BERT/data/paired_full_seqs_sep_val_no_ids_small_SPACE_separated.txt'\n","#test_file_path = '/ibmm_data2/oas_database/paired_lea_tmp/paired_model/train_test_val_datasets/heavy_sep_light_seq/paired_full_seqs_sep_test_no_ids_space_separated_SMALL.txt'"]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":true},"outputs":[],"source":["train_df = load_data(train_file_path)\n","val_df = load_data(val_file_path)\n","#test_df = load_data(test_file_path)\n","\n","\n","encoder_max_length = 200\n","decoder_max_length = 200\n","\n","def process_data_to_model_inputs(batch):\n","    # tokenize the inputs and labels\n","    inputs = tokenizer(batch[\"light\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n","    outputs = tokenizer(batch[\"heavy\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n","\n","    batch[\"input_ids\"] = inputs.input_ids\n","    batch[\"attention_mask\"] = inputs.attention_mask\n","    #batch[\"decoder_input_ids\"] = outputs.input_ids\n","    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n","    batch[\"labels\"] = outputs.input_ids.copy()\n","\n","    # Ignore PAD token in the labels\n","    batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n","\n","    return batch"]},{"cell_type":"code","execution_count":44,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 200/200 [00:00<00:00, 847.23 examples/s]\n","Map: 100%|██████████| 50/50 [00:00<00:00, 821.70 examples/s]\n","Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"]},{"name":"stdout","output_type":"stream","text":["first example heavy and light seq {'heavy': 'Q V Q L Q E S G P G L V K P S E T L S L T C T V S G G S I S G F Y W S W I R Q S P G K G L E W I A Y I Y F S G S T N Y N P S L K S R V T L S V D T S K N Q F S L K L S S V T A A D S A V Y Y C A R D V G P Y N S I S P G R Y Y F D Y W G P G T L V T V S S', 'light': 'Q S A L T Q P A S V S G S P G Q S I T I S C T G T S S D V G N Y N L V S W Y Q H H P G K A P K L M I Y E V S K R P S G I S N R F S G S K S G N T A S L T I S G L Q A D D E A D Y Y C C S Y A G S R I L Y V F G S G T K V T V L'}, {'heavy': 'Q V Q L Q E S G P G L V K P S E T L S L T C T V S G G S I S S Y H W S W I R Q P P G K G L E W I G Y M Y Y S G S T N Y N P S L K S R V T I S V D T S K T Q F S L K L S S V T T A D T A V Y Y C A R G R L I W S A D Y T G G D Y F D P W G Q G I L V T V S S', 'light': 'Q S A L T Q P A S V S G S P G Q S I T I S C T G S S S D V G S Y N L V S W Y Q Q H P G K A P K L M I Y E V S K R P S G V S N R F S G S K S G N T A S L T I S G L Q A E D E A Q Y Y C C S Y G G R N F H V L F G G G T E L T V L'}\n"]}],"source":["# Convert the dataframes to Hugging Face datasets\n","train_dataset = Dataset.from_pandas(train_df[['heavy', 'light']])\n","val_dataset = Dataset.from_pandas(val_df[['heavy', 'light']])\n","#test_dataset = Dataset.from_pandas(test_df[['heavy', 'light']])\n","\n","\n","train_data = train_dataset.map(\n","    process_data_to_model_inputs,\n","    batched=True,\n","    batch_size=batch_size,\n",")\n","\n","# \"decoder_input_ids\",\n","train_data.set_format(\n","    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_attention_mask\", \"labels\"],\n",")\n","\n","val_data = val_dataset.map(\n","    process_data_to_model_inputs,\n","    batched=True,\n","    batch_size=batch_size,\n",")\n","\n","# \"decoder_input_ids\",\n","val_data.set_format(\n","    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_attention_mask\", \"labels\"],\n",")\n","\n","\n","# test_data = test_dataset.map(\n","#     process_data_to_model_inputs,   \n","#     batched=True,\n","#     batch_size=batch_size,\n","# )   \n","\n","# # \"decoder_input_ids\",\n","# test_data.set_format(\n","#     type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_attention_mask\", \"labels\"],\n","# )\n","\n","\n","\n","\n","# print heavy and light seq from the first example in the training data (train_dataset)\n","print(f\"first example heavy and light seq {train_dataset[0]}, {train_dataset[1]}\")\n","\n","\n","# Initialize the trainer\n","trainer = Seq2SeqAdapterTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=val_data,\n","    data_collator=data_collator,\n","    adapter_names=[\"seq2seq_adapter\"],\n",")\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["GenerationConfig {\n","  \"decoder_start_token_id\": 2,\n","  \"do_sample\": true,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 3,\n","  \"length_penalty\": -2.0,\n","  \"max_length\": 512,\n","  \"min_length\": 50,\n","  \"no_repeat_ngram_size\": 2,\n","  \"num_beams\": 3,\n","  \"output_hidden_states\": true,\n","  \"output_logits\": true,\n","  \"output_scores\": true,\n","  \"pad_token_id\": 0,\n","  \"return_dict_in_generate\": true,\n","  \"temperature\": 0.001,\n","  \"vocab_size\": 30\n","}"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["model.generation_config"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["model.config.decoder_start_token_id = tokenizer.cls_token_id\n","model.config.eos_token_id = tokenizer.sep_token_id\n","model.config.pad_token_id = tokenizer.pad_token_id"]},{"cell_type":"code","execution_count":47,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"]},{"ename":"OutOfMemoryError","evalue":"Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py\", line 626, in forward\n    decoder_outputs = self.decoder(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 1201, in forward\n    outputs = self.bert(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/adapters/context.py\", line 116, in wrapper_func\n    results = f(self, *args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/adapters/model_mixin.py\", line 1350, in forward\n    return super().forward(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 988, in forward\n    encoder_outputs = self.encoder(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 582, in forward\n    layer_outputs = layer_module(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1582, in _call_impl\n    result = forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 498, in forward\n    cross_attention_outputs = self.crossattention(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 411, in forward\n    attention_output = self.output(self_outputs[0], hidden_states)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/adapters/models/bert/modeling_bert.py\", line 149, in forward\n    hidden_states = self.bottleneck_layer_forward(hidden_states, input_tensor, self.LayerNorm)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/adapters/methods/bottleneck.py\", line 369, in bottleneck_layer_forward\n    hidden_states = last_adapter.post_forward(hidden_states, input_hidden_states, residual_input, layer_norm)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/adapters/methods/modeling.py\", line 218, in post_forward\n    hidden_states = layer_norm(hidden_states + input_tensor)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/normalization.py\", line 201, in forward\n    return F.layer_norm(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/functional.py\", line 2573, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#print(f\"trainer.get_train_dataloader().collate_fn: {trainer.get_train_dataloader().collate_fn}\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#trainer.evaluate()\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2209\u001b[0m ):\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m~/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/trainer.py:3138\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3137\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3138\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3141\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/trainer.py:3161\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3160\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3161\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m~/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n","File \u001b[0;32m~/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:108\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    106\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 108\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","File \u001b[0;32m~/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/_utils.py:705\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n","\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py\", line 626, in forward\n    decoder_outputs = self.decoder(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 1201, in forward\n    outputs = self.bert(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/adapters/context.py\", line 116, in wrapper_func\n    results = f(self, *args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/adapters/model_mixin.py\", line 1350, in forward\n    return super().forward(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 988, in forward\n    encoder_outputs = self.encoder(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 582, in forward\n    layer_outputs = layer_module(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1582, in _call_impl\n    result = forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 498, in forward\n    cross_attention_outputs = self.crossattention(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 411, in forward\n    attention_output = self.output(self_outputs[0], hidden_states)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/adapters/models/bert/modeling_bert.py\", line 149, in forward\n    hidden_states = self.bottleneck_layer_forward(hidden_states, input_tensor, self.LayerNorm)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/adapters/methods/bottleneck.py\", line 369, in bottleneck_layer_forward\n    hidden_states = last_adapter.post_forward(hidden_states, input_hidden_states, residual_input, layer_norm)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/adapters/methods/modeling.py\", line 218, in post_forward\n    hidden_states = layer_norm(hidden_states + input_tensor)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/modules/normalization.py\", line 201, in forward\n    return F.layer_norm(\n  File \"/home/leab/anaconda3/envs/adap_2/lib/python3.9/site-packages/torch/nn/functional.py\", line 2573, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \n"]}],"source":["#print(f\"trainer.get_train_dataloader().collate_fn: {trainer.get_train_dataloader().collate_fn}\")\n","\n","# Train the model\n","trainer.train()\n","#trainer.evaluate()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_prompt = \"S T G V A F M E I N G L R S D D T A T Y F C A I N R V G D R G S N P S Y F Q D W G Q G T R V T V S S \"\n","print(f\"input_prompt: {input_prompt}\")\n","\n","inputs = tokenizer(input_prompt, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n","input_ids = inputs.input_ids.to(device)\n","attention_mask = inputs.attention_mask.to(device)\n","\n","print(f\"attention_mask: {attention_mask}\")\n","\n","#input_ids = tokenizer.encode(input_prompt, return_tensors=\"pt\").to(device)\n","print(f\"input_ids: {input_ids}\")\n","\n","# Generate text using the model\n","generated_seq = model.generate(input_ids=input_ids, \n","                               attention_mask=attention_mask, \n","                               max_length=100, \n","                               output_scores=True, \n","                               return_dict_in_generate=True)\n","\n","# Turn output scores to probabilities\n","# generated_seq_probs = torch.nn.functional.softmax(generated_seq['scores'][0], dim=-1)\n","\n","# Access the first element in the generated sequence\n","sequence = generated_seq[\"sequences\"][0]\n","\n","# Print the generated sequences and probabilities\n","print(f\"encoded heavy sequence: {sequence}.\")\n","\n","# Convert the generated IDs back to text\n","generated_text = tokenizer.decode(sequence, skip_special_tokens=True)\n","\n","print(\"decoded heavy sequence: \", generated_text)\n","\n","# print(test_data)\n","\n","# Load your test data\n","test_file_path = '/kaggle/input/test-file/paired_full_seqs_sep_test_no_ids_space_separated_SMALL.txt'\n","test_df = load_data(test_file_path)\n","\n","\n","# extract the light sequences from test_df\n","light_sequences = test_df[\"light\"]\n","\n","print(\"light_sequences: \", light_sequences)\n","print(f\"length of light sequences {len(light_sequences)}\")\n","\n","generated_heavy_seqs = []\n","\n","# Iterate through each sequence in the test dataset\n","for i in range(50):\n","    inputs = tokenizer(light_sequences[i], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n","    input_ids = inputs.input_ids.to(device)\n","    attention_mask = inputs.attention_mask.to(device)\n","\n","    generated_seq = model.generate(input_ids=input_ids, \n","                               attention_mask=attention_mask, \n","                               max_length=100, \n","                               output_scores=True, \n","                               return_dict_in_generate=True,\n","                                   generation_config=generation_config)\n","    \n","    # Access the first element in the generated sequence\n","    sequence = generated_seq[\"sequences\"][0]\n","\n","    # Print the generated sequences and probabilities\n","    print(f\"encoded heavy sequence: {sequence}.\")\n","\n","    # Convert the generated IDs back to text\n","    generated_text = tokenizer.decode(sequence, skip_special_tokens=True)\n","\n","    print(\"decoded heavy sequence: \", generated_text)\n","\n","    generated_heavy_seqs.append(generated_text)\n","\n","\n","print(\"generated_heavy_seqs:\")\n","# print each generated sequence on new line\n","for seq in generated_heavy_seqs:\n","    print(seq)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5122894,"sourceId":8568345,"sourceType":"datasetVersion"},{"datasetId":5122911,"sourceId":8568364,"sourceType":"datasetVersion"},{"datasetId":5294232,"sourceId":8803254,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}
