{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leab/anaconda3/envs/bug_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ran it with conda env bug_env\n",
    "# Now the imports\n",
    "import os\n",
    "import sys\n",
    "#from google.colab import auth, drive\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertConfig, BertForPreTraining, BertLMHeadModel, BertTokenizer, logging\n",
    "from transformers.data.datasets.language_modeling import TextDatasetForNextSentencePrediction\n",
    "from transformers import pipeline, Trainer, TrainingArguments\n",
    "from transformers import AutoConfig, AutoModel\n",
    "from transformers import LineByLineTextDataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "# from nlp import load_dataset\n",
    "# from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import seqeval\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pytz     # for time zone\n",
    "import gzip\n",
    "import csv\n",
    "import pickle\n",
    "import re\n",
    "import copy\n",
    "# set the pathnames and authenticate for my google bucket\n",
    "#project_id = 'serene-mender-286105'\n",
    "#!gcloud config set project {project_id}\n",
    "BUCKET_NAME = 'clinical_bert_bucket'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading model= 2024-04-22 05:05:17.917044-07:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leab/anaconda3/envs/bug_env/lib/python3.9/site-packages/transformers/training_args.py:1449: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/leab/anaconda3/envs/bug_env/lib/python3.9/site-packages/transformers/data/datasets/language_modeling.py:360: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start building train_dataset= 2024-04-22 05:05:38.864242-07:00\n",
      "start building eval_dataset= 2024-04-22 05:05:38.869612-07:00\n",
      "start building trainer= 2024-04-22 05:05:38.872436-07:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/leab/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sun Mar 31 12:42:24 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished= 2024-04-22 05:08:25.508310-07:00\n"
     ]
    }
   ],
   "source": [
    "PST = pytz.timezone('US/Pacific')\n",
    "!mkdir \"pytorch_finetuned_model\"\n",
    "!rm -rf \"pytorch_finetuned_model/*\"\n",
    "!mkdir \"pytorch_finetuned_log\"\n",
    "!rm -rf \"pytorch_finetuned_log/*\"\n",
    "\n",
    "#instantiate the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "#instantiate the model\n",
    "print(\"start loading model=\",datetime.now(PST))\n",
    "# model = BertLMHeadModel.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForPreTraining.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# define the arguments for the trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='pytorch_finetuned_model',          # output directory\n",
    "    num_train_epochs=3,              # total # of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training (try 16 if needed)\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='pytorch_finetuned_log',     # directory for storing logs\n",
    "    do_train=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=2\n",
    ")\n",
    "\n",
    "# prepare the training and validation data files\n",
    "with open(\"sent_train.txt\",\"w\") as f_out:\n",
    "  f_out.write(\"This is the first training sentence.\\n\")\n",
    "  f_out.write(\"This is the second training sentence.\\n\")\n",
    "  f_out.write(\"\\n This is the 3 training sentence.\\n\")\n",
    "  f_out.write(\"This is the 4 training sentence.\\n\")\n",
    "  f_out.write(\"\\nThis is the 5 training sentence.\\n\")\n",
    "  f_out.write(\"This is the 6 training sentence.\\n\")\n",
    "with open(\"sent_eval.txt\",\"w\") as f_out:\n",
    "  f_out.write(\"This is the first eval sentence.\\n\")\n",
    "  f_out.write(\"This is the second eval sentence.\\n\")\n",
    "  f_out.write(\"\\nThis is the 3 eval sentence.\\n\")\n",
    "  f_out.write(\"This is the 4 eval sentence.\\n\")\n",
    "\n",
    "# prepare the train_dataset\n",
    "print(\"start building train_dataset=\",datetime.now(PST))\n",
    "train_dataset = TextDatasetForNextSentencePrediction(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"sent_train.txt\",\n",
    "    block_size=128\n",
    ")\n",
    "\n",
    "print(\"start building eval_dataset=\",datetime.now(PST))\n",
    "eval_dataset = TextDatasetForNextSentencePrediction(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"sent_eval.txt\",\n",
    "    block_size=128\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "# Instantiate the trainer\n",
    "print(\"start building trainer=\",datetime.now(PST))\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    eval_dataset=eval_dataset            # evaluation dataset\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "import evaluate\n",
    "metric = evaluate.load(\"accuracy\", )\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_logits_for_metrics\n",
    "    labels = labels.reshape(-1)\n",
    "    preds = preds.reshape(-1)\n",
    "    mask = labels != -100\n",
    "    labels = labels[mask]\n",
    "    preds = preds[mask]\n",
    "    return metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "print(\"finished=\",datetime.now(PST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>9.265621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=3.486131032307943, metrics={'train_runtime': 0.6914, 'train_samples_per_second': 17.355, 'train_steps_per_second': 4.339, 'total_flos': 149075907840.0, 'train_loss': 3.486131032307943, 'epoch': 3.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now do training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bug_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
